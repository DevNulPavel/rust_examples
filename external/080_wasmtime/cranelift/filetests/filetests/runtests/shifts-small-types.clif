test run
target aarch64

; TODO: Merge this with the main shifts file when x86_64 & s390x passes these.

function %ishl_i16_i64(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
    v2 = ishl.i16 v0, v1
    return v2
}
; run: %ishl_i16_i64(0x0000, 0) == 0x0000
; run: %ishl_i16_i64(0x0000, 1) == 0x0000
; run: %ishl_i16_i64(0x000f, 0) == 0x000f
; run: %ishl_i16_i64(0x000f, 4) == 0x00f0
; run: %ishl_i16_i64(0x0004, 16) == 0x0004
; run: %ishl_i16_i64(0x0004, 17) == 0x0008
; run: %ishl_i16_i64(0x0004, 18) == 0x0010

function %ishl_i16_i32(i16, i32) -> i16 {
block0(v0: i16, v1: i32):
    v2 = ishl.i16 v0, v1
    return v2
}
; run: %ishl_i16_i32(0x0000, 0) == 0x0000
; run: %ishl_i16_i32(0x0000, 1) == 0x0000
; run: %ishl_i16_i32(0x000f, 0) == 0x000f
; run: %ishl_i16_i32(0x000f, 4) == 0x00f0
; run: %ishl_i16_i32(0x0004, 16) == 0x0004
; run: %ishl_i16_i32(0x0004, 17) == 0x0008
; run: %ishl_i16_i32(0x0004, 18) == 0x0010

function %ishl_i16_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
    v2 = ishl.i16 v0, v1
    return v2
}
; run: %ishl_i16_i16(0x0000, 0) == 0x0000
; run: %ishl_i16_i16(0x0000, 1) == 0x0000
; run: %ishl_i16_i16(0x000f, 0) == 0x000f
; run: %ishl_i16_i16(0x000f, 4) == 0x00f0
; run: %ishl_i16_i16(0x0004, 16) == 0x0004
; run: %ishl_i16_i16(0x0004, 17) == 0x0008
; run: %ishl_i16_i16(0x0004, 18) == 0x0010

function %ishl_i16_i8(i16, i8) -> i16 {
block0(v0: i16, v1: i8):
    v2 = ishl.i16 v0, v1
    return v2
}
; run: %ishl_i16_i8(0x0000, 0) == 0x0000
; run: %ishl_i16_i8(0x0000, 1) == 0x0000
; run: %ishl_i16_i8(0x000f, 0) == 0x000f
; run: %ishl_i16_i8(0x000f, 4) == 0x00f0
; run: %ishl_i16_i8(0x0004, 16) == 0x0004
; run: %ishl_i16_i8(0x0004, 17) == 0x0008
; run: %ishl_i16_i8(0x0004, 18) == 0x0010


function %ishl_i8_i64(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
    v2 = ishl.i8 v0, v1
    return v2
}
; run: %ishl_i8_i64(0x00, 0) == 0x00
; run: %ishl_i8_i64(0x00, 1) == 0x00
; run: %ishl_i8_i64(0x0f, 0) == 0x0f
; run: %ishl_i8_i64(0x0f, 4) == 0xf0
; run: %ishl_i8_i64(0x04, 8) == 0x04
; run: %ishl_i8_i64(0x04, 9) == 0x08
; run: %ishl_i8_i64(0x04, 10) == 0x10

function %ishl_i8_i32(i8, i32) -> i8 {
block0(v0: i8, v1: i32):
    v2 = ishl.i8 v0, v1
    return v2
}
; run: %ishl_i8_i32(0x00, 0) == 0x00
; run: %ishl_i8_i32(0x00, 1) == 0x00
; run: %ishl_i8_i32(0x0f, 0) == 0x0f
; run: %ishl_i8_i32(0x0f, 4) == 0xf0
; run: %ishl_i8_i32(0x04, 8) == 0x04
; run: %ishl_i8_i32(0x04, 9) == 0x08
; run: %ishl_i8_i32(0x04, 10) == 0x10

function %ishl_i8_i16(i8, i16) -> i8 {
block0(v0: i8, v1: i16):
    v2 = ishl.i8 v0, v1
    return v2
}
; run: %ishl_i8_i16(0x00, 0) == 0x00
; run: %ishl_i8_i16(0x00, 1) == 0x00
; run: %ishl_i8_i16(0x0f, 0) == 0x0f
; run: %ishl_i8_i16(0x0f, 4) == 0xf0
; run: %ishl_i8_i16(0x04, 8) == 0x04
; run: %ishl_i8_i16(0x04, 9) == 0x08
; run: %ishl_i8_i16(0x04, 10) == 0x10

function %ishl_i8_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = ishl.i8 v0, v1
    return v2
}
; run: %ishl_i8_i8(0x00, 0) == 0x00
; run: %ishl_i8_i8(0x00, 1) == 0x00
; run: %ishl_i8_i8(0x0f, 0) == 0x0f
; run: %ishl_i8_i8(0x0f, 4) == 0xf0
; run: %ishl_i8_i8(0x04, 8) == 0x04
; run: %ishl_i8_i8(0x04, 9) == 0x08
; run: %ishl_i8_i8(0x04, 10) == 0x10



function %ushr_i16_i64(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
    v2 = ushr.i16 v0, v1
    return v2
}
; run: %ushr_i16_i64(0x1000, 0) == 0x1000
; run: %ushr_i16_i64(0x1000, 1) == 0x0800
; run: %ushr_i16_i64(0xf000, 0) == 0xf000
; run: %ushr_i16_i64(0xf000, 4) == 0x0f00
; run: %ushr_i16_i64(0x4000, 16) == 0x4000
; run: %ushr_i16_i64(0x4000, 17) == 0x2000
; run: %ushr_i16_i64(0x4000, 18) == 0x1000

function %ushr_i16_i32(i16, i32) -> i16 {
block0(v0: i16, v1: i32):
    v2 = ushr.i16 v0, v1
    return v2
}
; run: %ushr_i16_i32(0x1000, 0) == 0x1000
; run: %ushr_i16_i32(0x1000, 1) == 0x0800
; run: %ushr_i16_i32(0xf000, 0) == 0xf000
; run: %ushr_i16_i32(0xf000, 4) == 0x0f00
; run: %ushr_i16_i32(0x4000, 16) == 0x4000
; run: %ushr_i16_i32(0x4000, 17) == 0x2000
; run: %ushr_i16_i32(0x4000, 18) == 0x1000

function %ushr_i16_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
    v2 = ushr.i16 v0, v1
    return v2
}
; run: %ushr_i16_i16(0x1000, 0) == 0x1000
; run: %ushr_i16_i16(0x1000, 1) == 0x0800
; run: %ushr_i16_i16(0xf000, 0) == 0xf000
; run: %ushr_i16_i16(0xf000, 4) == 0x0f00
; run: %ushr_i16_i16(0x4000, 16) == 0x4000
; run: %ushr_i16_i16(0x4000, 17) == 0x2000
; run: %ushr_i16_i16(0x4000, 18) == 0x1000

function %ushr_i16_i8(i16, i8) -> i16 {
block0(v0: i16, v1: i8):
    v2 = ushr.i16 v0, v1
    return v2
}
; run: %ushr_i16_i8(0x1000, 0) == 0x1000
; run: %ushr_i16_i8(0x1000, 1) == 0x0800
; run: %ushr_i16_i8(0xf000, 0) == 0xf000
; run: %ushr_i16_i8(0xf000, 4) == 0x0f00
; run: %ushr_i16_i8(0x4000, 16) == 0x4000
; run: %ushr_i16_i8(0x4000, 17) == 0x2000
; run: %ushr_i16_i8(0x4000, 18) == 0x1000

function %ushr_i8_i64(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
    v2 = ushr.i8 v0, v1
    return v2
}
; run: %ushr_i8_i64(0x10, 0) == 0x10
; run: %ushr_i8_i64(0x10, 1) == 0x08
; run: %ushr_i8_i64(0xf0, 0) == 0xf0
; run: %ushr_i8_i64(0xf0, 4) == 0x0f
; run: %ushr_i8_i64(0x40, 8) == 0x40
; run: %ushr_i8_i64(0x40, 9) == 0x20
; run: %ushr_i8_i64(0x40, 10) == 0x10

function %ushr_i8_i32(i8, i32) -> i8 {
block0(v0: i8, v1: i32):
    v2 = ushr.i8 v0, v1
    return v2
}
; run: %ushr_i8_i32(0x10, 0) == 0x10
; run: %ushr_i8_i32(0x10, 1) == 0x08
; run: %ushr_i8_i32(0xf0, 0) == 0xf0
; run: %ushr_i8_i32(0xf0, 4) == 0x0f
; run: %ushr_i8_i32(0x40, 8) == 0x40
; run: %ushr_i8_i32(0x40, 9) == 0x20
; run: %ushr_i8_i32(0x40, 10) == 0x10

function %ushr_i8_i16(i8, i16) -> i8 {
block0(v0: i8, v1: i16):
    v2 = ushr.i8 v0, v1
    return v2
}
; run: %ushr_i8_i16(0x10, 0) == 0x10
; run: %ushr_i8_i16(0x10, 1) == 0x08
; run: %ushr_i8_i16(0xf0, 0) == 0xf0
; run: %ushr_i8_i16(0xf0, 4) == 0x0f
; run: %ushr_i8_i16(0x40, 8) == 0x40
; run: %ushr_i8_i16(0x40, 9) == 0x20
; run: %ushr_i8_i16(0x40, 10) == 0x10

function %ushr_i8_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = ushr.i8 v0, v1
    return v2
}
; run: %ushr_i8_i8(0x10, 0) == 0x10
; run: %ushr_i8_i8(0x10, 1) == 0x08
; run: %ushr_i8_i8(0xf0, 0) == 0xf0
; run: %ushr_i8_i8(0xf0, 4) == 0x0f
; run: %ushr_i8_i8(0x40, 8) == 0x40
; run: %ushr_i8_i8(0x40, 9) == 0x20
; run: %ushr_i8_i8(0x40, 10) == 0x10



function %sshr_i16_i64(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
    v2 = sshr.i16 v0, v1
    return v2
}
; run: %sshr_i16_i64(0x8000, 0) == 0x8000
; run: %sshr_i16_i64(0x8000, 1) == 0xC000
; run: %sshr_i16_i64(0xf000, 0) == 0xf000
; run: %sshr_i16_i64(0xf000, 4) == 0xff00
; run: %sshr_i16_i64(0x4000, 16) == 0x4000
; run: %sshr_i16_i64(0x4000, 17) == 0x2000
; run: %sshr_i16_i64(0x4000, 18) == 0x1000

function %sshr_i16_i32(i16, i32) -> i16 {
block0(v0: i16, v1: i32):
    v2 = sshr.i16 v0, v1
    return v2
}
; run: %sshr_i16_i32(0x8000, 0) == 0x8000
; run: %sshr_i16_i32(0x8000, 1) == 0xC000
; run: %sshr_i16_i32(0xf000, 0) == 0xf000
; run: %sshr_i16_i32(0xf000, 4) == 0xff00
; run: %sshr_i16_i32(0x4000, 16) == 0x4000
; run: %sshr_i16_i32(0x4000, 17) == 0x2000
; run: %sshr_i16_i32(0x4000, 18) == 0x1000

function %sshr_i16_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
    v2 = sshr.i16 v0, v1
    return v2
}
; run: %sshr_i16_i16(0x8000, 0) == 0x8000
; run: %sshr_i16_i16(0x8000, 1) == 0xC000
; run: %sshr_i16_i16(0xf000, 0) == 0xf000
; run: %sshr_i16_i16(0xf000, 4) == 0xff00
; run: %sshr_i16_i16(0x4000, 16) == 0x4000
; run: %sshr_i16_i16(0x4000, 17) == 0x2000
; run: %sshr_i16_i16(0x4000, 18) == 0x1000

function %sshr_i16_i8(i16, i8) -> i16 {
block0(v0: i16, v1: i8):
    v2 = sshr.i16 v0, v1
    return v2
}
; run: %sshr_i16_i8(0x8000, 0) == 0x8000
; run: %sshr_i16_i8(0x8000, 1) == 0xC000
; run: %sshr_i16_i8(0xf000, 0) == 0xf000
; run: %sshr_i16_i8(0xf000, 4) == 0xff00
; run: %sshr_i16_i8(0x4000, 16) == 0x4000
; run: %sshr_i16_i8(0x4000, 17) == 0x2000
; run: %sshr_i16_i8(0x4000, 18) == 0x1000

function %sshr_i8_i64(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
    v2 = sshr.i8 v0, v1
    return v2
}
; run: %sshr_i8_i64(0x80, 0) == 0x80
; run: %sshr_i8_i64(0x80, 1) == 0xC0
; run: %sshr_i8_i64(0xf0, 0) == 0xf0
; run: %sshr_i8_i64(0xf0, 4) == 0xff
; run: %sshr_i8_i64(0x40, 8) == 0x40
; run: %sshr_i8_i64(0x40, 9) == 0x20
; run: %sshr_i8_i64(0x40, 10) == 0x10

function %sshr_i8_i32(i8, i32) -> i8 {
block0(v0: i8, v1: i32):
    v2 = sshr.i8 v0, v1
    return v2
}
; run: %sshr_i8_i32(0x80, 0) == 0x80
; run: %sshr_i8_i32(0x80, 1) == 0xC0
; run: %sshr_i8_i32(0xf0, 0) == 0xf0
; run: %sshr_i8_i32(0xf0, 4) == 0xff
; run: %sshr_i8_i32(0x40, 8) == 0x40
; run: %sshr_i8_i32(0x40, 9) == 0x20
; run: %sshr_i8_i32(0x40, 10) == 0x10

function %sshr_i8_i16(i8, i16) -> i8 {
block0(v0: i8, v1: i16):
    v2 = sshr.i8 v0, v1
    return v2
}
; run: %sshr_i8_i16(0x80, 0) == 0x80
; run: %sshr_i8_i16(0x80, 1) == 0xC0
; run: %sshr_i8_i16(0xf0, 0) == 0xf0
; run: %sshr_i8_i16(0xf0, 4) == 0xff
; run: %sshr_i8_i16(0x40, 8) == 0x40
; run: %sshr_i8_i16(0x40, 9) == 0x20
; run: %sshr_i8_i16(0x40, 10) == 0x10

function %sshr_i8_i64(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
    v2 = sshr.i8 v0, v1
    return v2
}
; run: %sshr_i8_i64(0x80, 0) == 0x80
; run: %sshr_i8_i64(0x80, 1) == 0xC0
; run: %sshr_i8_i64(0xf0, 0) == 0xf0
; run: %sshr_i8_i64(0xf0, 4) == 0xff
; run: %sshr_i8_i64(0x40, 8) == 0x40
; run: %sshr_i8_i64(0x40, 9) == 0x20
; run: %sshr_i8_i64(0x40, 10) == 0x10
