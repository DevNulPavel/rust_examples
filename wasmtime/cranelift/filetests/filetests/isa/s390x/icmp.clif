test compile
target s390x

function %icmp_slt_i64(i64, i64) -> b1 {
block0(v0: i64, v1: i64):
  v2 = icmp.i64 slt v0, v1
  return v2
}

; check:  cgr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_ext32(i64, i32) -> b1 {
block0(v0: i64, v1: i32):
  v2 = sextend.i64 v1
  v3 = icmp.i64 slt v0, v2
  return v3
}

; check:  cgfr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_imm16(i64) -> b1 {
block0(v0: i64):
  v1 = iconst.i64 1
  v2 = icmp.i64 slt v0, v1
  return v2
}

; check:  cghi %r2, 1
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_imm32(i64) -> b1 {
block0(v0: i64):
  v1 = iconst.i64 32768
  v2 = icmp.i64 slt v0, v1
  return v2
}

; check:  cgfi %r2, 32768
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_mem(i64, i64) -> b1 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3 = icmp.i64 slt v0, v2
  return v3
}

; check:  cg %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_sym(i64) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i64):
  v1 = symbol_value.i64 gv0
  v2 = load.i64 v1
  v3 = icmp.i64 slt v0, v2
  return v3
}

; check:  cgrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_mem_ext16(i64, i64) -> b1 {
block0(v0: i64, v1: i64):
  v2 = sload16.i64 v1
  v3 = icmp.i64 slt v0, v2
  return v3
}

; check:  cgh %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_sym_ext16(i64) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i64):
  v1 = symbol_value.i64 gv0
  v2 = sload16.i64 v1
  v3 = icmp.i64 slt v0, v2
  return v3
}

; check:  cghrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_mem_ext32(i64, i64) -> b1 {
block0(v0: i64, v1: i64):
  v2 = sload32.i64 v1
  v3 = icmp.i64 slt v0, v2
  return v3
}

; check:  cgf %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i64_sym_ext32(i64) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i64):
  v1 = symbol_value.i64 gv0
  v2 = sload32.i64 v1
  v3 = icmp.i64 slt v0, v2
  return v3
}

; check:  cgfrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32(i32, i32) -> b1 {
block0(v0: i32, v1: i32):
  v2 = icmp.i32 slt v0, v1
  return v2
}

; check:  cr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32_imm16(i32) -> b1 {
block0(v0: i32):
  v1 = iconst.i32 1
  v2 = icmp.i32 slt v0, v1
  return v2
}

; check:  chi %r2, 1
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32_imm(i32) -> b1 {
block0(v0: i32):
  v1 = iconst.i32 32768
  v2 = icmp.i32 slt v0, v1
  return v2
}

; check:  cfi %r2, 32768
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32_mem(i32, i64) -> b1 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3 = icmp.i32 slt v0, v2
  return v3
}

; check:  c %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32_memoff(i32, i64) -> b1 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3 = icmp.i32 slt v0, v2
  return v3
}

; check:  cy %r2, 4096(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32_sym(i32) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i32):
  v1 = symbol_value.i64 gv0
  v2 = load.i32 v1
  v3 = icmp.i32 slt v0, v2
  return v3
}

; check:  crl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32_mem_ext16(i32, i64) -> b1 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1
  v3 = icmp.i32 slt v0, v2
  return v3
}

; check:  ch %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32_memoff_ext16(i32, i64) -> b1 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1+4096
  v3 = icmp.i32 slt v0, v2
  return v3
}

; check:  chy %r2, 4096(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i32_sym_ext16(i32) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i32):
  v1 = symbol_value.i64 gv0
  v2 = sload16.i32 v1
  v3 = icmp.i32 slt v0, v2
  return v3
}

; check:  chrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i16(i16, i16) -> b1 {
block0(v0: i16, v1: i16):
  v2 = icmp.i16 slt v0, v1
  return v2
}

; check:  lhr %r2, %r2
; nextln: lhr %r3, %r3
; nextln: cr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i16_imm(i16) -> b1 {
block0(v0: i16):
  v1 = iconst.i16 1
  v2 = icmp.i16 slt v0, v1
  return v2
}

; check:  lhr %r2, %r2
; nextln: chi %r2, 1
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i16_mem(i16, i64) -> b1 {
block0(v0: i16, v1: i64):
  v2 = load.i16 v1
  v3 = icmp.i16 slt v0, v2
  return v3
}

; check:  lhr %r2, %r2
; nextln: ch %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i16_sym(i16) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i16):
  v1 = symbol_value.i64 gv0
  v2 = load.i16 v1
  v3 = icmp.i16 slt v0, v2
  return v3
}

; check:  lhr %r2, %r2
; nextln: chrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i8(i8, i8) -> b1 {
block0(v0: i8, v1: i8):
  v2 = icmp.i8 slt v0, v1
  return v2
}

; check:  lbr %r2, %r2
; nextln: lbr %r3, %r3
; nextln: cr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i8_imm(i8) -> b1 {
block0(v0: i8):
  v1 = iconst.i8 1
  v2 = icmp.i8 slt v0, v1
  return v2
}

; check:  lbr %r2, %r2
; nextln: chi %r2, 1
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_slt_i8_mem(i8, i64) -> b1 {
block0(v0: i8, v1: i64):
  v2 = load.i8 v1
  v3 = icmp.i8 slt v0, v2
  return v3
}

; check:  lbr %r2, %r2
; nextln: lb %r3, 0(%r3)
; nextln: cr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64(i64, i64) -> b1 {
block0(v0: i64, v1: i64):
  v2 = icmp.i64 ult v0, v1
  return v2
}

; check:  clgr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64_ext32(i64, i32) -> b1 {
block0(v0: i64, v1: i32):
  v2 = uextend.i64 v1
  v3 = icmp.i64 ult v0, v2
  return v3
}

; check:  clgfr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64_imm(i64) -> b1 {
block0(v0: i64):
  v1 = iconst.i64 1
  v2 = icmp.i64 ult v0, v1
  return v2
}

; check:  clgfi %r2, 1
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64_mem(i64, i64) -> b1 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3 = icmp.i64 ult v0, v2
  return v3
}

; check:  clg %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64_sym(i64) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i64):
  v1 = symbol_value.i64 gv0
  v2 = load.i64 v1
  v3 = icmp.i64 ult v0, v2
  return v3
}

; check:  clgrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64_mem_ext32(i64, i64) -> b1 {
block0(v0: i64, v1: i64):
  v2 = uload32.i64 v1
  v3 = icmp.i64 ult v0, v2
  return v3
}

; check:  clgf %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64_sym_ext32(i64) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i64):
  v1 = symbol_value.i64 gv0
  v2 = uload32.i64 v1
  v3 = icmp.i64 ult v0, v2
  return v3
}

; check:  clgfrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64_mem_ext16(i64, i64) -> b1 {
block0(v0: i64, v1: i64):
  v2 = uload16.i64 v1
  v3 = icmp.i64 ult v0, v2
  return v3
}

; check:  llgh %r3, 0(%r3)
; check:  clgr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i64_sym_ext16(i64) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i64):
  v1 = symbol_value.i64 gv0
  v2 = uload16.i64 v1
  v3 = icmp.i64 ult v0, v2
  return v3
}

; check:  clghrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i32(i32, i32) -> b1 {
block0(v0: i32, v1: i32):
  v2 = icmp.i32 ult v0, v1
  return v2
}

; check:  clr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i32_imm(i32) -> b1 {
block0(v0: i32):
  v1 = iconst.i32 1
  v2 = icmp.i32 ult v0, v1
  return v2
}

; check:  clfi %r2, 1
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i32_mem(i32, i64) -> b1 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3 = icmp.i32 ult v0, v2
  return v3
}

; check:  cl %r2, 0(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i32_memoff(i32, i64) -> b1 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3 = icmp.i32 ult v0, v2
  return v3
}

; check:  cly %r2, 4096(%r3)
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i32_sym(i32) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i32):
  v1 = symbol_value.i64 gv0
  v2 = load.i32 v1
  v3 = icmp.i32 ult v0, v2
  return v3
}

; check:  clrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i32_mem_ext16(i32, i64) -> b1 {
block0(v0: i32, v1: i64):
  v2 = uload16.i32 v1
  v3 = icmp.i32 ult v0, v2
  return v3
}

; check:  llh %r3, 0(%r3)
; check:  clr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i32_sym_ext16(i32) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i32):
  v1 = symbol_value.i64 gv0
  v2 = uload16.i32 v1
  v3 = icmp.i32 ult v0, v2
  return v3
}

; check:  clhrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i16(i16, i16) -> b1 {
block0(v0: i16, v1: i16):
  v2 = icmp.i16 ult v0, v1
  return v2
}

; check:  llhr %r2, %r2
; nextln: llhr %r3, %r3
; nextln: clr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i16_imm(i16) -> b1 {
block0(v0: i16):
  v1 = iconst.i16 1
  v2 = icmp.i16 ult v0, v1
  return v2
}

; check:  llhr %r2, %r2
; nextln: clfi %r2, 1
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i16_mem(i16, i64) -> b1 {
block0(v0: i16, v1: i64):
  v2 = load.i16 v1
  v3 = icmp.i16 ult v0, v2
  return v3
}

; check:  llhr %r2, %r2
; nextln: llh %r3, 0(%r3)
; nextln: clr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i16_mem(i16) -> b1 {
  gv0 = symbol colocated %sym
block0(v0: i16):
  v1 = symbol_value.i64 gv0
  v2 = load.i16 v1
  v3 = icmp.i16 ult v0, v2
  return v3
}

; check:  llhr %r2, %r2
; nextln: clhrl %r2, %sym + 0
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i8(i8, i8) -> b1 {
block0(v0: i8, v1: i8):
  v2 = icmp.i8 ult v0, v1
  return v2
}

; check:  llcr %r2, %r2
; nextln: llcr %r3, %r3
; nextln: clr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i8_imm(i8) -> b1 {
block0(v0: i8):
  v1 = iconst.i8 1
  v2 = icmp.i8 ult v0, v1
  return v2
}

; check:  llcr %r2, %r2
; nextln: clfi %r2, 1
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

function %icmp_ult_i8_mem(i8, i64) -> b1 {
block0(v0: i8, v1: i64):
  v2 = load.i8 v1
  v3 = icmp.i8 ult v0, v2
  return v3
}

; check:  llcr %r2, %r2
; nextln: llc %r3, 0(%r3)
; nextln: clr %r2, %r3
; nextln: lhi %r2, 0
; nextln: lochil %r2, 1
; nextln: br %r14

